{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "from sklearn.utils import extmath\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy import sparse, stats, spatial\n",
    "from scipy.sparse import csr_matrix\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = './data/Main/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preparing the datasets\n",
    "\n",
    "## 1.1. Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64500, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trackID</th>\n",
       "      <th>trackTitle</th>\n",
       "      <th>artistName</th>\n",
       "      <th>trackPopularity</th>\n",
       "      <th>releaseDate</th>\n",
       "      <th>artistFollowers</th>\n",
       "      <th>topGenre1</th>\n",
       "      <th>topGenre2</th>\n",
       "      <th>artistID</th>\n",
       "      <th>albumID</th>\n",
       "      <th>songID</th>\n",
       "      <th>audio_Duration_ms</th>\n",
       "      <th>set_subset</th>\n",
       "      <th>set_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The Room Of Stairs</td>\n",
       "      <td>Harold Budd</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>30414.0</td>\n",
       "      <td>Electronic/Dance</td>\n",
       "      <td>Classical</td>\n",
       "      <td>3uOCouLFR4bVx0XeiQJSbl</td>\n",
       "      <td>3jq7b66l8MswqDmi0mxzjq</td>\n",
       "      <td>SOAAADD12AB018A9DD</td>\n",
       "      <td>321133</td>\n",
       "      <td>medium</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>(I'm Gonna Start) Living Again If It Kills Me</td>\n",
       "      <td>Dave Edmunds</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1981</td>\n",
       "      <td>28604.0</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Blues</td>\n",
       "      <td>65Gh3BfK84aTIugiRCgLBA</td>\n",
       "      <td>0upTl2RUS4gmStWBlXjt9l</td>\n",
       "      <td>SOAAADE12A6D4F80CC</td>\n",
       "      <td>199088</td>\n",
       "      <td>medium</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>KRYSAR (LIVE)</td>\n",
       "      <td>LANDA DANIEL</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6rSpV5hdCNJ4v1i602nj22</td>\n",
       "      <td>7uvLu2RAki7aKiASSxJPzi</td>\n",
       "      <td>SOAAADF12A8C13DF62</td>\n",
       "      <td>200880</td>\n",
       "      <td>medium</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trackID                                     trackTitle    artistName  \\\n",
       "0        0                             The Room Of Stairs   Harold Budd   \n",
       "1        1  (I'm Gonna Start) Living Again If It Kills Me  Dave Edmunds   \n",
       "2        2                                  KRYSAR (LIVE)  LANDA DANIEL   \n",
       "\n",
       "   trackPopularity  releaseDate  artistFollowers         topGenre1  topGenre2  \\\n",
       "0             11.0         2000          30414.0  Electronic/Dance  Classical   \n",
       "1              5.0         1981          28604.0              Rock      Blues   \n",
       "2             15.0         2003              NaN               NaN        NaN   \n",
       "\n",
       "                 artistID                 albumID              songID  \\\n",
       "0  3uOCouLFR4bVx0XeiQJSbl  3jq7b66l8MswqDmi0mxzjq  SOAAADD12AB018A9DD   \n",
       "1  65Gh3BfK84aTIugiRCgLBA  0upTl2RUS4gmStWBlXjt9l  SOAAADE12A6D4F80CC   \n",
       "2  6rSpV5hdCNJ4v1i602nj22  7uvLu2RAki7aKiASSxJPzi  SOAAADF12A8C13DF62   \n",
       "\n",
       "   audio_Duration_ms set_subset set_split  \n",
       "0             321133     medium     train  \n",
       "1             199088     medium     train  \n",
       "2             200880     medium     train  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Loading 'tracks' dataset\n",
    "tracks = pd.read_csv(data_folder+'tracks.csv', \n",
    "                        index_col=0, encoding='utf-8', low_memory=False)\n",
    "# Mapping trackID to numeric ID\n",
    "# Getting unique trackID\n",
    "unique_trackID = tracks.trackID.unique()\n",
    "# Creating a dictionary to assign numeric ID to each trackID\n",
    "dict_trackID = dict(zip(unique_trackID, range(unique_trackID.size)))\n",
    "# Mapping trackID to numeric ID using 'dict_trackID' dictionary\n",
    "tracks['trackID'] = tracks.trackID.map(dict_trackID)\n",
    "\n",
    "print(tracks.shape)\n",
    "tracks.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/numpy/lib/arraysetops.py:472: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4911782, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>songID</th>\n",
       "      <th>counts</th>\n",
       "      <th>trackID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOBSUJE12A6D4F8CF5</td>\n",
       "      <td>2</td>\n",
       "      <td>2ECKXkpPAxky87ohawpaeD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOBVFZR12A6D4F8AE3</td>\n",
       "      <td>1</td>\n",
       "      <td>5WjXULJvSlMxuies9diz1Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOBXALG12A8C13C108</td>\n",
       "      <td>1</td>\n",
       "      <td>1bqi9YEdZweX9H6JuSQ6Qw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     userID              songID  counts  \\\n",
       "0  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBSUJE12A6D4F8CF5       2   \n",
       "1  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBVFZR12A6D4F8AE3       1   \n",
       "2  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBXALG12A8C13C108       1   \n",
       "\n",
       "                  trackID  \n",
       "0  2ECKXkpPAxky87ohawpaeD  \n",
       "1  5WjXULJvSlMxuies9diz1Q  \n",
       "2  1bqi9YEdZweX9H6JuSQ6Qw  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Loading playlists dataset\n",
    "user_profile = pd.read_csv(data_folder+'userProfile.csv', \n",
    "                        index_col=0, encoding='utf-8', low_memory=False)\n",
    "\n",
    "# Keeping only tracks that exists in tracks dataframe\n",
    "user_profile = user_profile[user_profile.trackID.isin(list(dict_trackID.keys()))]\n",
    "\n",
    "print(user_profile.shape)\n",
    "user_profile.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4911782, 3)\n"
     ]
    }
   ],
   "source": [
    "### Mapping userID to numeric ID\n",
    "# getting unique userID\n",
    "unique_userID = user_profile.userID.unique()\n",
    "# Creating a dictionary to assign numeric ID to current user ID\n",
    "dict_userID = dict(zip(unique_userID, range(unique_userID.size)))\n",
    "# Mapping userID using prepared dictionary\n",
    "user_profile.userID = user_profile.userID.map(dict_userID)\n",
    "# Mapping trackID to numeric ID using 'dict_trackID' dictionary\n",
    "user_profile.trackID = user_profile.trackID.map(dict_trackID)\n",
    "user_profile = user_profile[['userID', 'trackID', 'counts']]\n",
    "\n",
    "print(user_profile.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64500, 518)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chroma_cens_kurtosis_01</th>\n",
       "      <th>chroma_cens_kurtosis_02</th>\n",
       "      <th>chroma_cens_kurtosis_03</th>\n",
       "      <th>chroma_cens_kurtosis_04</th>\n",
       "      <th>chroma_cens_kurtosis_05</th>\n",
       "      <th>chroma_cens_kurtosis_06</th>\n",
       "      <th>chroma_cens_kurtosis_07</th>\n",
       "      <th>chroma_cens_kurtosis_08</th>\n",
       "      <th>chroma_cens_kurtosis_09</th>\n",
       "      <th>chroma_cens_kurtosis_10</th>\n",
       "      <th>...</th>\n",
       "      <th>tonnetz_std_04</th>\n",
       "      <th>tonnetz_std_05</th>\n",
       "      <th>tonnetz_std_06</th>\n",
       "      <th>zcr_kurtosis_01</th>\n",
       "      <th>zcr_max_01</th>\n",
       "      <th>zcr_mean_01</th>\n",
       "      <th>zcr_median_01</th>\n",
       "      <th>zcr_min_01</th>\n",
       "      <th>zcr_skew_01</th>\n",
       "      <th>zcr_std_01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.720673</td>\n",
       "      <td>4.240027</td>\n",
       "      <td>-0.618995</td>\n",
       "      <td>0.426698</td>\n",
       "      <td>-0.226265</td>\n",
       "      <td>-0.209698</td>\n",
       "      <td>-0.317341</td>\n",
       "      <td>-1.345874</td>\n",
       "      <td>-0.586116</td>\n",
       "      <td>-0.931247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084099</td>\n",
       "      <td>0.017905</td>\n",
       "      <td>0.017880</td>\n",
       "      <td>3.022421</td>\n",
       "      <td>0.400879</td>\n",
       "      <td>0.093924</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.030273</td>\n",
       "      <td>1.610670</td>\n",
       "      <td>0.054095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.370662</td>\n",
       "      <td>-0.287299</td>\n",
       "      <td>1.182948</td>\n",
       "      <td>-0.952800</td>\n",
       "      <td>-0.790715</td>\n",
       "      <td>-0.504890</td>\n",
       "      <td>-0.491160</td>\n",
       "      <td>0.696574</td>\n",
       "      <td>0.054538</td>\n",
       "      <td>0.780068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127805</td>\n",
       "      <td>0.020186</td>\n",
       "      <td>0.023055</td>\n",
       "      <td>13.629067</td>\n",
       "      <td>0.286621</td>\n",
       "      <td>0.046816</td>\n",
       "      <td>0.042969</td>\n",
       "      <td>0.008301</td>\n",
       "      <td>2.550661</td>\n",
       "      <td>0.024498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.769198</td>\n",
       "      <td>-0.571088</td>\n",
       "      <td>-0.860308</td>\n",
       "      <td>0.437645</td>\n",
       "      <td>-1.027899</td>\n",
       "      <td>1.226321</td>\n",
       "      <td>-0.928717</td>\n",
       "      <td>1.680385</td>\n",
       "      <td>-1.276514</td>\n",
       "      <td>-0.994085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084305</td>\n",
       "      <td>0.018808</td>\n",
       "      <td>0.020520</td>\n",
       "      <td>10.252457</td>\n",
       "      <td>0.222168</td>\n",
       "      <td>0.053373</td>\n",
       "      <td>0.049316</td>\n",
       "      <td>0.013184</td>\n",
       "      <td>2.536385</td>\n",
       "      <td>0.023678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 518 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   chroma_cens_kurtosis_01  chroma_cens_kurtosis_02  chroma_cens_kurtosis_03  \\\n",
       "0                 0.720673                 4.240027                -0.618995   \n",
       "1                -0.370662                -0.287299                 1.182948   \n",
       "2                -0.769198                -0.571088                -0.860308   \n",
       "\n",
       "   chroma_cens_kurtosis_04  chroma_cens_kurtosis_05  chroma_cens_kurtosis_06  \\\n",
       "0                 0.426698                -0.226265                -0.209698   \n",
       "1                -0.952800                -0.790715                -0.504890   \n",
       "2                 0.437645                -1.027899                 1.226321   \n",
       "\n",
       "   chroma_cens_kurtosis_07  chroma_cens_kurtosis_08  chroma_cens_kurtosis_09  \\\n",
       "0                -0.317341                -1.345874                -0.586116   \n",
       "1                -0.491160                 0.696574                 0.054538   \n",
       "2                -0.928717                 1.680385                -1.276514   \n",
       "\n",
       "   chroma_cens_kurtosis_10     ...      tonnetz_std_04  tonnetz_std_05  \\\n",
       "0                -0.931247     ...            0.084099        0.017905   \n",
       "1                 0.780068     ...            0.127805        0.020186   \n",
       "2                -0.994085     ...            0.084305        0.018808   \n",
       "\n",
       "   tonnetz_std_06  zcr_kurtosis_01  zcr_max_01  zcr_mean_01  zcr_median_01  \\\n",
       "0        0.017880         3.022421    0.400879     0.093924       0.078125   \n",
       "1        0.023055        13.629067    0.286621     0.046816       0.042969   \n",
       "2        0.020520        10.252457    0.222168     0.053373       0.049316   \n",
       "\n",
       "   zcr_min_01  zcr_skew_01  zcr_std_01  \n",
       "0    0.030273     1.610670    0.054095  \n",
       "1    0.008301     2.550661    0.024498  \n",
       "2    0.013184     2.536385    0.023678  \n",
       "\n",
       "[3 rows x 518 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading 'librosa_features' dataset\n",
    "features = pd.read_csv(data_folder+'librosa_features.csv', \n",
    "                        index_col=0, header=[0,1,2], encoding='utf-8', low_memory=False)\n",
    "\n",
    "# Converting multi-index columns to flat index\n",
    "features.columns = [ '_'.join(x) for x in features.columns ]\n",
    "\n",
    "# Filter Librosa feature to the songs that exists in tracks dataframe\n",
    "features = features[features.index.isin(list(dict_trackID.keys()))]\n",
    "\n",
    "# Mapping trackID to numeric ID using 'dict_trackID' dictionary\n",
    "features.index = features.index.map(dict_trackID).astype(int)\n",
    "\n",
    "print(features.shape)\n",
    "features.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Filtering to 12,000 songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracks dataframe shape after filtering:  (12900, 14)\n",
      "Features dataframe after  (12900, 518)\n"
     ]
    }
   ],
   "source": [
    "# Filtering tracks to be left by only small subset\n",
    "tracks_s = tracks[tracks.set_subset=='small']#.iloc[:2000,:]\n",
    "print('Tracks dataframe shape after filtering: ',tracks_s.shape)\n",
    "\n",
    "# Filtering features based on filtered 'tracks_s' dataframe\n",
    "features_s  = features[features.index.isin(tracks_s.trackID)]\n",
    "# Filling NAs\n",
    "features_s = features_s.fillna(0)\n",
    "print('Features dataframe after ',features_s.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Songs similarity network based on Librosa Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Sparsifying the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12900, 12900)\n"
     ]
    }
   ],
   "source": [
    "#######################################################################################################\n",
    "###### Standardizing features, since the algorithm works better with standardized features #######\n",
    "#######################################################################################################\n",
    "\n",
    "# Standardizing the 'features' dataframe\n",
    "scaler_features = StandardScaler()\n",
    "features_scaled = scaler_features.fit_transform(features_s)\n",
    "features_scaled = pd.DataFrame(features_scaled, index=features_s.index, columns=features_s.columns)\n",
    "\n",
    "# Compute the distance between the tracks for creating adjacency matrix\n",
    "### Using pdist to calculate the pairwise distance between each track\n",
    "distances = spatial.distance.pdist(features_scaled, metric='cosine')\n",
    "distances = spatial.distance.squareform(distances)\n",
    "\n",
    "print(distances.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing weights matrix\n",
    "kernel_width = distances.mean()\n",
    "weights = np.exp(-1*(distances**2/(kernel_width**2)))\n",
    "#Setting the diagonal to zero\n",
    "np.fill_diagonal(weights, 0)\n",
    "\n",
    "# First step of sparsifying: Based on weights\n",
    "sp_thr = 0.1\n",
    "weights[weights<=sp_thr] = 0\n",
    "\n",
    "# We sparsify based on outdegree of each node: a[0,:] show out-going edges\n",
    "### This is because in the algorithms that we will use, \n",
    "### ...in-degree contains information that we don't want to lose\n",
    "Edges = 30\n",
    "sort_idx = np.argsort(weights, axis=1)\n",
    "#Leaving all but the 50 strongest edges\n",
    "for i,index in enumerate(sort_idx):\n",
    "    weights[i, index[:-Edges]] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Creating NetworkX graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Getting sparse matrix\n",
    "weights_sp = sparse.csr_matrix(weights)\n",
    "# Building a graph from Sparse CSR matrix\n",
    "G_tracks = nx.from_scipy_sparse_matrix(weights_sp, create_using=nx.DiGraph(), edge_attribute='weight')\n",
    "# Relabeling the nodes (name of nodes: TrackID)\n",
    "G_tracks = nx.relabel_nodes(G_tracks, dict(zip(range(len(tracks_s.trackID.values)), tracks_s.trackID.values)))\n",
    "\n",
    "### Getting connected components\n",
    "components = []\n",
    "for component in nx.strongly_connected_components(G_tracks):\n",
    "    components.append(component)\n",
    "# Sorting the connected components based on their number of nodes\n",
    "components.sort(key=lambda x: len(x))\n",
    "# Creating a subgraph of G_tracks whihc contains selected songs \n",
    "### (here 500 songs selected in \"creating utility matrix\" step)\n",
    "G_tracks = G_tracks.subgraph(sorted(list(components[-1])))\n",
    "\n",
    "# Adding meta data to the graph\n",
    "for node, dic in G_tracks.nodes(data=True):\n",
    "    G_tracks.node[node]['trackTitle'] = tracks.loc[tracks.trackID==node,'trackTitle'].values[0]\n",
    "    G_tracks.node[node]['artistName'] = tracks.loc[tracks.trackID==node,'artistName'].values[0]\n",
    "    G_tracks.node[node]['topGenre'] = tracks.loc[tracks.trackID==node,'topGenre1'].values[0]\n",
    "    G_tracks.node[node]['audioDuration'] = tracks.loc[tracks.trackID==node,'audio_Duration_ms'].values[0]//1000\n",
    "    G_tracks.node[node]['trackPopularity'] = tracks.loc[tracks.trackID==node,'trackPopularity'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of nodes names\n",
    "nodes_name = tracks_s.trackID.values \n",
    "nodes_name = nodes_name[np.isin(nodes_name, list(G_tracks.nodes()))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Creating output files for Gephi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32772</td>\n",
       "      <td>Adam Arcuragi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Ingmar Nordströms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>The Wolfgang Press</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>Bobby Pullido</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32786</td>\n",
       "      <td>Agnostic Front</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    node               label\n",
       "0  32772       Adam Arcuragi\n",
       "1      5   Ingmar Nordströms\n",
       "2     10  The Wolfgang Press\n",
       "3     11       Bobby Pullido\n",
       "4  32786      Agnostic Front"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_id_gephi = []\n",
    "nodes_labels_gephi = []\n",
    "for i, node in enumerate(G_tracks.nodes(data=True)):\n",
    "    nodes_labels_gephi.append(node[1]['artistName'])\n",
    "    nodes_id_gephi.append(node[0])\n",
    "# Creating the dataframe    \n",
    "gephi_nodes_df = pd.DataFrame(dict(node=nodes_id_gephi, label=nodes_labels_gephi))\n",
    "# Saving the nodes dataframe\n",
    "#gephi_nodes_df.to_csv(data_folder+'gephi_nodes.csv', sep=';', encoding='utf-8', index=False)\n",
    "\n",
    "gephi_nodes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32772</td>\n",
       "      <td>3918</td>\n",
       "      <td>0.897446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32772</td>\n",
       "      <td>8181</td>\n",
       "      <td>0.898069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32772</td>\n",
       "      <td>8522</td>\n",
       "      <td>0.882573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32772</td>\n",
       "      <td>10249</td>\n",
       "      <td>0.901878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32772</td>\n",
       "      <td>10549</td>\n",
       "      <td>0.880082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source  target    weight\n",
       "0   32772    3918  0.897446\n",
       "1   32772    8181  0.898069\n",
       "2   32772    8522  0.882573\n",
       "3   32772   10249  0.901878\n",
       "4   32772   10549  0.880082"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_id_gephi = []\n",
    "target_id_gephi = []\n",
    "weights_gephi = []\n",
    "for i, edge in enumerate(G_tracks.edges(data=True)):\n",
    "    source_id_gephi.append(edge[0])\n",
    "    target_id_gephi.append(edge[1])\n",
    "    weights_gephi.append(edge[2]['weight'])\n",
    "# Creating the dataframe   \n",
    "gephi_edges_df = pd.DataFrame(dict(source=source_id_gephi, target=target_id_gephi, \n",
    "                                   weight=weights_gephi))\n",
    "# Saving the nodes dataframe\n",
    "#gephi_edges_df.to_csv(data_folder+'gephi_edges.csv', encoding='utf-8', index=False)\n",
    "\n",
    "gephi_edges_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Songs similarity network extracted from User profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Creating the Utility matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/numpy/lib/arraysetops.py:472: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "# Loading the saved mapped 'user_profile'\n",
    "user_profile_s = pd.read_csv(data_folder+'user_profile_mapped_s.csv', encoding='utf-8', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a sparse matrix from 'user_profile' dataframe\n",
    "userID_cat = CategoricalDtype(user_profile_s.userID.unique(), ordered=True)\n",
    "trackID_cat = CategoricalDtype(nodes_name, ordered=True)\n",
    "\n",
    "row = user_profile_s.userID.astype(userID_cat).cat.codes\n",
    "col = user_profile_s.trackID.astype(trackID_cat).cat.codes\n",
    "sparse_utility = csr_matrix((user_profile_s['counts'], (row, col)), \\\n",
    "                             shape=(userID_cat.categories.size, trackID_cat.categories.size))\n",
    "\n",
    "# Defining the sparse DataFrame\n",
    "utility_df = pd.SparseDataFrame(sparse_utility, \\\n",
    "                         index=userID_cat.categories, \\\n",
    "                         columns=trackID_cat.categories, \\\n",
    "                         default_fill_value=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Decomposing the User profile dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_components = 50\n",
    "U, S, V = extmath.randomized_svd(sparse_utility, n_components, n_oversamples=20, n_iter=10, \n",
    "                                               power_iteration_normalizer='QR', \n",
    "                                               transpose=False, flip_sign=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the distance between the tracks for creating adjacency matrix\n",
    "### Using pdist to calculate the pairwise distance between each track\n",
    "distances_h = spatial.distance.pdist(V.T, metric='cosine')\n",
    "distances_h = spatial.distance.squareform(distances_h)\n",
    "\n",
    "# Computing weights matrix\n",
    "kernel_width_h = distances_h.mean()\n",
    "weights_h = np.exp(-1*(distances_h**2/(kernel_width_h**2)))\n",
    "#Setting the diagonal to zero\n",
    "np.fill_diagonal(weights_h, 0)\n",
    "\n",
    "# First step of sparsifying: Based on weights\n",
    "sp_thr = 0.2\n",
    "weights_h[weights_h<=sp_thr] = 0\n",
    "\n",
    "# We sparsify based on outdegree of each node: a[0,:] show out-going edges\n",
    "### This is because in the algorithms that we will use, \n",
    "### ...in-degree contains information that we don't want to lose\n",
    "Edges = 30\n",
    "\n",
    "sort_idx = np.argsort(weights_h, axis=1)\n",
    "#Leaving all but the 50 strongest edges\n",
    "for i,index in enumerate(sort_idx):\n",
    "    weights_h[i, index[:-Edges]] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Creating the NetworkX graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting sparse matrix\n",
    "weights_sp = sparse.csr_matrix(weights_h)\n",
    "# Building a graph from Sparse CSR matrix\n",
    "G_tracks_h = nx.from_scipy_sparse_matrix(weights_sp, create_using=nx.DiGraph(), edge_attribute='weight')\n",
    "# Relabeling the nodes (name of nodes: TrackID)\n",
    "G_tracks_h = nx.relabel_nodes(G_tracks_h, dict(zip(range(len(utility_df.columns.values)), utility_df.columns.values)))\n",
    "\n",
    "# Adding meta data to the graph\n",
    "for node, dic in G_tracks_h.nodes(data=True):\n",
    "    G_tracks_h.node[node]['trackTitle'] = tracks.loc[tracks.trackID==node,'trackTitle'].values[0]\n",
    "    G_tracks_h.node[node]['artistName'] = tracks.loc[tracks.trackID==node,'artistName'].values[0]\n",
    "    G_tracks_h.node[node]['topGenre'] = tracks.loc[tracks.trackID==node,'topGenre1'].values[0]\n",
    "    G_tracks_h.node[node]['audioDuration'] = tracks.loc[tracks.trackID==node,'audio_Duration_ms'].values[0]//1000\n",
    "    G_tracks_h.node[node]['trackPopularity'] = tracks.loc[tracks.trackID==node,'trackPopularity'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Creating output files for Gephi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Ingmar Nordströms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>The Wolfgang Press</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>Bobby Pullido</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>London Elektricity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>Blitzen Trapper</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   node               label\n",
       "0     5   Ingmar Nordströms\n",
       "1    10  The Wolfgang Press\n",
       "2    11       Bobby Pullido\n",
       "3    21  London Elektricity\n",
       "4    22     Blitzen Trapper"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_id_gephi = []\n",
    "nodes_labels_gephi = []\n",
    "for i, node in enumerate(G_tracks_h.nodes(data=True)):\n",
    "    nodes_labels_gephi.append(node[1]['artistName'])\n",
    "    nodes_id_gephi.append(node[0])\n",
    "# Creating the dataframe \n",
    "gephi_nodes_df_h = pd.DataFrame(dict(node=nodes_id_gephi, label=nodes_labels_gephi))\n",
    "# Saving the nodes dataframe\n",
    "#gephi_nodes_df_h.to_csv(data_folder+'gephi_nodes_p.csv', sep=';', encoding='utf-8', index=False)\n",
    "\n",
    "gephi_nodes_df_h.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.991048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>6625</td>\n",
       "      <td>0.989474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>10272</td>\n",
       "      <td>0.994391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>10742</td>\n",
       "      <td>0.993712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>11411</td>\n",
       "      <td>0.990570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source  target    weight\n",
       "0       5    1000  0.991048\n",
       "1       5    6625  0.989474\n",
       "2       5   10272  0.994391\n",
       "3       5   10742  0.993712\n",
       "4       5   11411  0.990570"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_id_gephi = []\n",
    "target_id_gephi = []\n",
    "weights_gephi = []\n",
    "\n",
    "for i, edge in enumerate(G_tracks_h.edges(data=True)):\n",
    "    source_id_gephi.append(edge[0])\n",
    "    target_id_gephi.append(edge[1])\n",
    "    weights_gephi.append(edge[2]['weight'])\n",
    "# Creating the the dataframe\n",
    "gephi_edges_df_h = pd.DataFrame(dict(source=source_id_gephi, target=target_id_gephi, \n",
    "                                   weight=weights_gephi))\n",
    "# Saving the nodes dataframe\n",
    "#gephi_edges_df_h.to_csv(data_folder+'gephi_edges_p.csv', encoding='utf-8', index=False)\n",
    "\n",
    "gephi_edges_df_h.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
